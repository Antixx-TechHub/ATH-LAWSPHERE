# Development Environment - Local Setup

version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: pgvector/pgvector:pg16
    container_name: lawsphere-postgres-dev
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-lawsphere}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-lawsphere_dev}
      POSTGRES_DB: ${POSTGRES_DB:-lawsphere_dev}
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lawsphere"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lawsphere-dev

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: lawsphere-redis-dev
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_dev_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lawsphere-dev

  # AI Service (FastAPI)
  ai-service:
    build:
      context: .
      dockerfile: apps/ai-service/Dockerfile
    container_name: lawsphere-ai-dev
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-lawsphere}:${POSTGRES_PASSWORD:-lawsphere_dev}@postgres:5432/${POSTGRES_DB:-lawsphere_dev}
      REDIS_URL: redis://redis:6379
      NODE_ENV: development
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY:-}
      LANGSMITH_API_KEY: ${LANGSMITH_API_KEY:-}
      LANGCHAIN_TRACING_V2: ${LANGCHAIN_TRACING_V2:-false}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - ./apps/ai-service:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - lawsphere-dev
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Web Frontend (Next.js)
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
    container_name: lawsphere-web-dev
    restart: unless-stopped
    environment:
      NODE_ENV: development
      DATABASE_URL: postgresql://${POSTGRES_USER:-lawsphere}:${POSTGRES_PASSWORD:-lawsphere_dev}@postgres:5432/${POSTGRES_DB:-lawsphere_dev}
      AI_SERVICE_URL: http://ai-service:8000/api
      NEXTAUTH_URL: http://localhost:3000
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET:-dev-secret-change-in-production}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-}
      GITHUB_CLIENT_ID: ${GITHUB_CLIENT_ID:-}
      GITHUB_CLIENT_SECRET: ${GITHUB_CLIENT_SECRET:-}
    depends_on:
      postgres:
        condition: service_healthy
      ai-service:
        condition: service_healthy
    ports:
      - "3000:3000"
    volumes:
      - ./apps/web:/app
      - /app/node_modules
      - /app/.next
    networks:
      - lawsphere-dev
    command: npm run dev

  # Ollama - Local LLM Runtime (Optional but recommended)
  # Pull models with: docker-compose exec ollama ollama pull qwen2
  ollama:
    image: ollama/ollama:latest
    container_name: lawsphere-ollama-dev
    restart: unless-stopped
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
    volumes:
      - ollama_dev_data:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - lawsphere-dev
    # Uncomment for GPU support (NVIDIA)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  postgres_dev_data:
  redis_dev_data:
  ollama_dev_data:

networks:
  lawsphere-dev:
    driver: bridge
