# ===========================================
# PRODUCTION Environment Variables for AI Service
# Copy these to Railway environment variables
# ===========================================

# Application
APP_NAME=lawsphere-ai-service
APP_ENV=production
DEBUG=false
LOG_LEVEL=INFO

# Server (Railway sets PORT automatically)
HOST=0.0.0.0
PORT=8000
WORKERS=4

# Database (Railway PostgreSQL - get from Railway dashboard)
# Use asyncpg driver for async operations
DATABASE_URL=postgresql+asyncpg://postgres:PASSWORD@HOST:PORT/railway

# Redis (Railway Redis - get from Railway dashboard)
REDIS_URL=redis://default:PASSWORD@HOST:PORT

# ============================================
# AI Providers (choose one or more)
# ============================================

# RECOMMENDED: Groq (FREE tier - fast inference)
# Get API key: https://console.groq.com/keys
GROQ_API_KEY=

# Open-source model configuration
OPENSOURCE_PROVIDER=groq
OPENSOURCE_MODEL=llama-3.1-8b-instant
DEFAULT_MODEL=llama-3.1-8b-instant

# Alternative: OpenAI (paid)
OPENAI_API_KEY=

# Alternative: Anthropic (paid)
ANTHROPIC_API_KEY=

# Alternative: Google AI (paid)
GOOGLE_API_KEY=

# ============================================
# Local LLM (optional - requires GPU)
# ============================================
OLLAMA_ENABLED=false
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3.1

# ============================================
# Observability (optional but recommended)
# ============================================

# LangSmith Tracing
LANGCHAIN_TRACING_V2=false
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=lawsphere-production

# ============================================
# S3 Storage (if web app uses S3)
# ============================================
S3_BUCKET=lawsphere-files
S3_REGION=us-east-1
S3_ACCESS_KEY=
S3_SECRET_KEY=
S3_ENDPOINT=

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60
